{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-17T08:22:39.242006Z",
     "iopub.status.busy": "2025-01-17T08:22:39.241782Z",
     "iopub.status.idle": "2025-01-17T08:22:50.489185Z",
     "shell.execute_reply": "2025-01-17T08:22:50.488368Z",
     "shell.execute_reply.started": "2025-01-17T08:22:39.241986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/sskyisthelimit/DS_Internship.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:22:50.490535Z",
     "iopub.status.busy": "2025-01-17T08:22:50.490224Z",
     "iopub.status.idle": "2025-01-17T08:22:50.496968Z",
     "shell.execute_reply": "2025-01-17T08:22:50.496303Z",
     "shell.execute_reply.started": "2025-01-17T08:22:50.490511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd DS_Internship/CV/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:06.835503Z",
     "iopub.status.busy": "2025-01-17T08:23:06.835262Z",
     "iopub.status.idle": "2025-01-17T08:23:06.840797Z",
     "shell.execute_reply": "2025-01-17T08:23:06.840118Z",
     "shell.execute_reply.started": "2025-01-17T08:23:06.835481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:06.842154Z",
     "iopub.status.busy": "2025-01-17T08:23:06.841852Z",
     "iopub.status.idle": "2025-01-17T08:23:06.857198Z",
     "shell.execute_reply": "2025-01-17T08:23:06.856311Z",
     "shell.execute_reply.started": "2025-01-17T08:23:06.842125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd DS_Internship/CV/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:06.859405Z",
     "iopub.status.busy": "2025-01-17T08:23:06.859203Z",
     "iopub.status.idle": "2025-01-17T08:23:17.423559Z",
     "shell.execute_reply": "2025-01-17T08:23:17.422748Z",
     "shell.execute_reply.started": "2025-01-17T08:23:06.859387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone --quiet https://github.com/sskyisthelimit/LightGlueTune.git\n",
    "%cd LightGlueTune\n",
    "!python3 -m pip install --progress-bar off --quiet -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i didn't came up with approach to do it by calling one function from repo\n",
    "because of problem with importing lightglue in kaggle environment yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:17.425508Z",
     "iopub.status.busy": "2025-01-17T08:23:17.425047Z",
     "iopub.status.idle": "2025-01-17T08:23:25.165845Z",
     "shell.execute_reply": "2025-01-17T08:23:25.164985Z",
     "shell.execute_reply.started": "2025-01-17T08:23:17.425471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/DS_Internship/CV/LightGlueTune/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from lightglue import LightGlue, SuperPoint\n",
    "\n",
    "def initialize_models(device, max_num_keypoints):\n",
    "    ckpt_path = \"../assets/superpoint_official.pth\"\n",
    "    \n",
    "    extractor_model = SuperPoint(max_num_keypoints=max_num_keypoints,\n",
    "                                 ckpt_path=ckpt_path).eval().to(device)\n",
    "    \n",
    "    lg_ckpt_path = \"../assets/lightglue_official.pth\"\n",
    "    \n",
    "    matcher_model = LightGlue(\n",
    "        features=\"superpoint\",\n",
    "        custom=False,\n",
    "        ckpt_path=lg_ckpt_path).eval().to(device)\n",
    "    \n",
    "    return extractor_model, matcher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:25.167150Z",
     "iopub.status.busy": "2025-01-17T08:23:25.166664Z",
     "iopub.status.idle": "2025-01-17T08:23:25.171890Z",
     "shell.execute_reply": "2025-01-17T08:23:25.171176Z",
     "shell.execute_reply.started": "2025-01-17T08:23:25.167097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/DS_Internship/CV/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if to consider comment above i only need\n",
    "redefine 2 functions here initialize_models, eval_on_jp2_tiles (one that does main work)\n",
    "but i didn't think about DRY yesterday night\n",
    "so i will refactor when i will prepare better test dataset (check out comment in last cell of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T08:23:25.173606Z",
     "iopub.status.busy": "2025-01-17T08:23:25.173313Z",
     "iopub.status.idle": "2025-01-17T08:23:25.211666Z",
     "shell.execute_reply": "2025-01-17T08:23:25.211038Z",
     "shell.execute_reply.started": "2025-01-17T08:23:25.173578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np.random.seed(33)\n",
    "random.seed(33)\n",
    "torch.manual_seed(33)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import json\n",
    "from inference_utils import (load_torch_image,\n",
    "                             split_image,\n",
    "                             K)\n",
    "# lightglue doesn't show up as a module in kaggle\n",
    "# (i need manually cd into dir and import modules),\n",
    "# so import line below would cause an error\n",
    "\n",
    "# so to run evaluation you need define same initialize_models and import LightGlue, SuperPoint\n",
    "# from inference import initialize_models\n",
    "\n",
    "import collections.abc as collections\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "class MatchingDataset(Dataset):\n",
    "    def __init__(self, image_folder_path=None,\n",
    "                 all_tiles_paths=None):\n",
    "        super().__init__()\n",
    "        if image_folder_path:\n",
    "            all_tiles_paths = []\n",
    "            for image_path in glob.iglob(image_folder_path + '**/*.jp2', recursive=True):\n",
    "                all_tiles_paths.append(image_path)\n",
    "            self.tile_pairs = list(itertools.combinations(all_tiles_paths, 2))\n",
    "        elif isinstance(all_tiles_paths, list):\n",
    "            self.tile_pairs = list(itertools.combinations(all_tiles_paths, 2))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid init parameters\")\n",
    "        # kaggle time limitation \n",
    "        self.tile_pairs = random.sample(self.tile_pairs, 200)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tile_pairs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.tile_pairs[index]\n",
    "\n",
    "\n",
    "def rbd(data: dict) -> dict:\n",
    "    \"\"\"Remove batch dimension from elements in data\"\"\"\n",
    "    return {\n",
    "        k: v[0] if isinstance(v, (torch.Tensor, np.ndarray, list)) else v\n",
    "        for k, v in data.items()\n",
    "    }\n",
    "\n",
    "\n",
    "def map_tensor(input_, func):\n",
    "    string_classes = (str, bytes)\n",
    "    if isinstance(input_, string_classes):\n",
    "        return input_\n",
    "    elif isinstance(input_, collections.Mapping):\n",
    "        return {k: map_tensor(sample, func) for k, sample in input_.items()}\n",
    "    elif isinstance(input_, collections.Sequence):\n",
    "        return [map_tensor(sample, func) for sample in input_]\n",
    "    elif isinstance(input_, torch.Tensor):\n",
    "        return func(input_)\n",
    "    else:\n",
    "        return input_\n",
    "\n",
    "\n",
    "def batch_to_device(batch: dict, device: str = \"cpu\", non_blocking: bool = True):\n",
    "    \"\"\"Move batch (dict) to device\"\"\"\n",
    "\n",
    "    def _func(tensor):\n",
    "        return tensor.to(device=device, non_blocking=non_blocking).detach()\n",
    "\n",
    "    return map_tensor(batch, _func)\n",
    "\n",
    "\n",
    "def evaluate_metrics(extractor, matcher, img1, img2, device):\n",
    "    \"\"\"Evaluate key metrics for the SuperPoint + LightGlue pipeline.\"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    feats0 = extractor.extract(img1)\n",
    "    feats1 = extractor.extract(img2)\n",
    "\n",
    "    extraction_time = time.time() - start_time\n",
    "\n",
    "    start_matching = time.time()\n",
    "\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    data = [feats0, feats1, matches01]\n",
    "    # remove batch dim and move to target device\n",
    "    feats0, feats1, matches01 = [batch_to_device(rbd(x), device) for x in data]\n",
    "    matching_time = time.time() - start_matching\n",
    "\n",
    "    matching_scores = matches01[\"scores\"]\n",
    "    kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "\n",
    "    matched_kpts0, matched_kpts1 = kpts0[matches[..., 0]].cpu().numpy(), kpts1[matches[..., 1]].cpu().numpy()\n",
    "    kpts0, kpts1 = kpts0.cpu().numpy(), kpts1.cpu().numpy()\n",
    "    # Match Coverage\n",
    "    match_coverage_img1 = len(matched_kpts0) / len(kpts0) if len(kpts0) > 0 else 0\n",
    "    match_coverage_img2 = len(matched_kpts1) / len(kpts1) if len(kpts1) > 0 else 0\n",
    "\n",
    "    # Keypoint Displacement\n",
    "    displacements = np.linalg.norm(matched_kpts0 - matched_kpts1, axis=1)\n",
    "    avg_displacement = np.mean(displacements) if len(displacements) > 0 else 0\n",
    "    max_displacement = np.max(displacements) if len(displacements) > 0 else 0\n",
    "\n",
    "    # Mean Matching Score\n",
    "    mean_matching_score = np.mean(matching_scores.cpu().numpy()) if len(matching_scores) > 0 else 0\n",
    "\n",
    "    # Processing Time\n",
    "    metrics = {\n",
    "        \"match_coverage_img1\": match_coverage_img1,\n",
    "        \"match_coverage_img2\": match_coverage_img2,\n",
    "        \"avg_displacement\": avg_displacement,\n",
    "        \"max_displacement\": max_displacement,\n",
    "        \"mean_matching_score\": mean_matching_score,\n",
    "        \"extraction_time\": extraction_time,\n",
    "        \"matching_time\": matching_time,\n",
    "        \"total_time\": 0,\n",
    "        \"matches_len\": matched_kpts0.shape[0],\n",
    "        \"kpts0_len\": kpts0.shape[0],\n",
    "        \"kpts1_len\": kpts1.shape[0],\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def eval_on_jp2_tiles(args):\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(0)\n",
    "\n",
    "    eval_dataset = MatchingDataset(args[\"image_folder_path\"])\n",
    "    eval_dl = DataLoader(\n",
    "        eval_dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=4,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n",
    "    \n",
    "\n",
    "    device = args[\"device\"]\n",
    "    extractor, matcher = initialize_models(device, args[\"max_num_keypoints\"])\n",
    "\n",
    "    # Macro metrics aggregation\n",
    "    macro_metrics = {\n",
    "        \"match_coverage_img1\": [],\n",
    "        \"match_coverage_img2\": [],\n",
    "        \"avg_displacement\": [],\n",
    "        \"max_displacement\": [],\n",
    "        \"mean_matching_score\": [],\n",
    "        \"extraction_time\": [],\n",
    "        \"matching_time\": [],\n",
    "        \"total_time\": [],\n",
    "        \"matches_len\": [],\n",
    "        \"kpts0_len\": [],\n",
    "        \"kpts1_len\": [],\n",
    "    }\n",
    "    \n",
    "    for batch_idx, (path_img_1, path_img_2) in enumerate(eval_dl):\n",
    "        print(f\"Evaluating pair {batch_idx + 1}/{len(eval_dl)}: {path_img_1[0]} and {path_img_2[0]}\")\n",
    "    \n",
    "        start_time = time.time()  # Start timing for the full pair\n",
    "        img1 = load_torch_image(path_img_1[0], args[\"width\"], args[\"height\"]).to(device)\n",
    "        img2 = load_torch_image(path_img_2[0], args[\"width\"], args[\"height\"]).to(device)\n",
    "    \n",
    "        crp_1_img = split_image(img1, args[\"n_pair\"])\n",
    "        crp_2_img = split_image(img2, args[\"n_pair\"])\n",
    "    \n",
    "        dict_keys = list(crp_1_img.keys())\n",
    "    \n",
    "        # Initialize accumulators for pair-level metrics\n",
    "        pair_metrics = {\n",
    "            \"matches_len\": 0,\n",
    "            \"kpts0_len\": 0,\n",
    "            \"kpts1_len\": 0,\n",
    "            \"match_coverage_img1\": 0,\n",
    "            \"match_coverage_img2\": 0,\n",
    "            \"avg_displacement_sum\": 0,\n",
    "            \"extraction_time\": 0,\n",
    "            \"matching_time\": 0,\n",
    "            \"max_displacement\": 0,\n",
    "            \"mean_matching_score_sum\": 0,\n",
    "            \"crop_count\": 0,\n",
    "        }\n",
    "    \n",
    "        limit = int(args[\"n_pair\"] / 2) ** 2\n",
    "\n",
    "        for pair_index in range(limit):\n",
    "            crp1 = crp_1_img[dict_keys[pair_index]][\"image\"]\n",
    "            crp2 = crp_2_img[dict_keys[pair_index]][\"image\"]\n",
    "    \n",
    "            if torch.cuda.is_available():\n",
    "                crp1 = crp1.cuda(device).float()\n",
    "                crp2 = crp2.cuda(device).float()\n",
    "    \n",
    "            metrics = evaluate_metrics(\n",
    "                extractor,\n",
    "                matcher,\n",
    "                K.color.rgb_to_grayscale(crp1).to(device),\n",
    "                K.color.rgb_to_grayscale(crp2).to(device),\n",
    "                device\n",
    "            )\n",
    "    \n",
    "            # Accumulate metrics for the full pair\n",
    "            pair_metrics[\"matches_len\"] += metrics[\"matches_len\"]\n",
    "            pair_metrics[\"extraction_time\"] += metrics[\"extraction_time\"]\n",
    "            pair_metrics[\"matching_time\"] += metrics[\"matching_time\"]\n",
    "            pair_metrics[\"kpts0_len\"] += metrics[\"kpts0_len\"]\n",
    "            pair_metrics[\"kpts1_len\"] += metrics[\"kpts1_len\"]\n",
    "            pair_metrics[\"match_coverage_img1\"] += metrics[\"match_coverage_img1\"]\n",
    "            pair_metrics[\"match_coverage_img2\"] += metrics[\"match_coverage_img2\"]\n",
    "            pair_metrics[\"avg_displacement_sum\"] += metrics[\"avg_displacement\"] * metrics[\"matches_len\"]\n",
    "            pair_metrics[\"mean_matching_score_sum\"] += metrics[\"mean_matching_score\"] * metrics[\"matches_len\"]\n",
    "            pair_metrics[\"max_displacement\"] = max(pair_metrics[\"max_displacement\"], metrics[\"max_displacement\"])\n",
    "            pair_metrics[\"crop_count\"] += 1\n",
    "            del crp1, crp2\n",
    "    \n",
    "        total_time = time.time() - start_time  # Total time for the full pair\n",
    "    \n",
    "        # Finalize metrics for the pair\n",
    "        match_coverage_img1 = pair_metrics[\"match_coverage_img1\"] / pair_metrics[\"crop_count\"]\n",
    "        match_coverage_img2 = pair_metrics[\"match_coverage_img2\"] / pair_metrics[\"crop_count\"]\n",
    "        avg_displacement = (\n",
    "            pair_metrics[\"avg_displacement_sum\"] / pair_metrics[\"matches_len\"]\n",
    "            if pair_metrics[\"matches_len\"] > 0\n",
    "            else 0\n",
    "        )\n",
    "        mean_matching_score = (\n",
    "            pair_metrics[\"mean_matching_score_sum\"] / pair_metrics[\"matches_len\"]\n",
    "            if pair_metrics[\"matches_len\"] > 0\n",
    "            else 0\n",
    "        )\n",
    "    \n",
    "        # Add finalized pair-level metrics to macro_metrics\n",
    "        macro_metrics[\"match_coverage_img1\"].append(match_coverage_img1)\n",
    "        macro_metrics[\"match_coverage_img2\"].append(match_coverage_img2)\n",
    "        macro_metrics[\"avg_displacement\"].append(avg_displacement)\n",
    "        macro_metrics[\"max_displacement\"].append(pair_metrics[\"max_displacement\"])\n",
    "        macro_metrics[\"mean_matching_score\"].append(mean_matching_score)\n",
    "        macro_metrics[\"matches_len\"].append(pair_metrics[\"matches_len\"])\n",
    "        macro_metrics[\"kpts0_len\"].append(pair_metrics[\"kpts0_len\"])\n",
    "        macro_metrics[\"kpts1_len\"].append(pair_metrics[\"kpts1_len\"])\n",
    "        macro_metrics[\"extraction_time\"].append(pair_metrics[\"extraction_time\"])  # Keep using per-pair timing\n",
    "        macro_metrics[\"matching_time\"].append(pair_metrics[\"matching_time\"])\n",
    "        macro_metrics[\"total_time\"].append(total_time)\n",
    "\n",
    "    del img1, img2\n",
    "   \n",
    "    final_macro_metrics = {key: str(np.mean(values)) for key, values in macro_metrics.items()}\n",
    "\n",
    "    # Save macro metrics as JSON\n",
    "    save_path = f\"{args['save_dir']}/macro_metrics.json\"\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(final_macro_metrics, f, indent=4)\n",
    "    print(f\"Macro metrics saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_on_jp2_tiles(\n",
    "    {\n",
    "        \"image_folder_path\": \"/kaggle/input/satellite-test-set/\",\n",
    "        \"width\": 10980,\n",
    "        \"height\": 10980,\n",
    "        \"n_pair\": 20,\n",
    "        \"crop_width\": 1098,\n",
    "        \"crop_height\": 1098,\n",
    "        \"save_dir\": \"/kaggle/working/\",\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"max_num_keypoints\": 1500,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can check analyze results by looking at ./macro_metrics.json\n",
    "NOTE:\n",
    "1. Pairs were sampled randomly but i think that\n",
    "current dataset for testing is biased (i mean it doesn't align with real life task), why?\n",
    "    - Only one tile, 1 year time span\n",
    "    - i think metrics contibuted positively by short timespan tile image pairs\n",
    "\n",
    "(nevertheless i completed main task - prepare basic notebook for evaluation)\n",
    "\n",
    "conclusion:\n",
    "i will get more accurate results\n",
    "if i will sample multiple tiles from regions of ukraine with different landscapes, near the sea, mountains\n",
    "also from what i will sample i will get rid of frequent ones,\n",
    "will sample images with longer timespan between them"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6314610,
     "sourceId": 10215952,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 217083356,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
